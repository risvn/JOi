#!/bin/bash

# ----- Paths -----
# Whisper model + binary
whisper="../stt/bin/whisper-cli"
txt_model="../stt/models/ggml-tiny.bin"

# Audio setup
audio_file="../audio/speech.wav"
arecord -f S16_LE -r 16000 -c 1 -d 5 "$audio_file"

# LLaMA
export LD_LIBRARY_PATH="../llm/bin:$LD_LIBRARY_PATH"
model="../llm/bin/llama-cli"
path_to_gguf="../llm/models/tinyllama_1b_q4_chat.gguf"
tokens=78

# Piper TTS

piper="../tts/piper/piper"


#tts_model="../tts/voice/hfc_female/hfc_female.onnx"
#tts_model="../tts/voice/libritts/en_US-libritts-high.onnx"
tts_model="../tts/voice/libritts_r/en_US-libritts_r-medium.onnx"




# ----- Transcribe with Whisper -----

# ----- Transcribe with Whisper and extract tokens -----
"$whisper" -m "$txt_model" -f "$audio_file" -otxt > /dev/null

# Now read the output text file into a variable
transcript=$(cat "${audio_file}.txt")

# Show it on screen for debug (optional)
echo "📝 Transcript: $transcript"


# If Whisper output is empty, exit
if [ -z "$transcript" ]; then
  echo "❌ No transcription was generated."
  exit 1
fi

# ----- Generate response with LLaMA -----

# Generate the text with LLaMA, pass it to Piper for speech synthesis, and play the audio
"$model" -m "$path_to_gguf" -p "$transcript" -n "$tokens" | \
tee /dev/tty | \
"$piper" --model "$tts_model" --output-raw | \
aplay -f S16_LE -r 22050


